# Kitoboy
Система помощи в противодействии суициду

# Дата релиза

15.05.2025-03.06.2025

Следите за новостями в нашей [группе в Телеграме](https://t.me/+axSZVk-mLHVkMjEy).

# О системе

Система помогает оценивать уровень суицидального статуса для пользователей социальных сетей по их открытым постам. Для этого в систему загружаются посты со страницы пользователя, затем к каждому посту модели машинного обучения делают предсказания о наличии каких-либо признаков, связанных с суицидальным поведением. 

Есть две главные модели, предсказывающие важные классы признаков. Первый это пресуицидальные признаки (сигналы) — те, что склоняют человека к суициду. Второй это антисуицидальные признаки — те, что удерживают человека. Предсказания моделей позволяют отсеять нерелевантные посты, составляющие до 80 процентов от объема постов, что позволяет волонтерам сосредоточиться на главном. На основе предсказаний система позволяет оценить динамику проявления того или иного признака во времени. Наконец, волонтер может выставить суицидальный статус пользователю социальных сетей.

Система позволяет вести учёт. Имеется возможность создать карточку, которая отражает информацию о реальном человеке, найденную по открытым постам. Поскольку реальный человек может иметь несколько аккаунтов в социальных сетях, к одной карточке может быть присоединено несколько аккаунтов. Также, карточка имеет отдельный суицидальный статус, связанный именно с реальным человеком, а не аккаунтом. 

**Важное замечание**: собирая персональные данные о реальном человеке даже по открытой информации, вы должны иметь право на такую деятельность.

# Технические требования

Для запуска системы вам понадобится машина, у которой минимально выполнены следующие требования:
* Работает на базе операционной системы Linux. Тест запуска проводился на:
  * Ubuntu 18.04
  * Debian 9
* Установлена программа docker-compose версии не ниже 2.29.7.
* Установлена программа Docker версии не ниже 20.10.21.
* Имеется не менее 16 Гигабайт оперативной памяти.
* Установлен процессор Intel семейства Core i7 8 поколения.

# Быстрый старт

## Запуск системы:

1. Склонируйте репозиторий
```
https://github.com/psytechlab/kitoboy.git
```
2. Подготовьте окружение

Для этого в корне репозитория создайте файл окружения `.env` на основе шаблона `.env.example`. Далее в созданном файле необходимо изменить значение переменной `NODE_ENV` на `production`. В переменной `VITE_APP_HOST` нужно указать имя хоста, на котором разворачивается приложение. При локальном запуске ее значение можно оставить без изменений. `DB_NAME` и `DB_HOST` должны остаться без изменения. Остальные переменные можно оставить со значениями по умолчанию, либо изменить на строковые значения. Пояснения к переменным:
* VITE_APP_HOST —  доменное имя или IP-адрес сервера. Заполняется  для  случая,  когда платформа разворачивается на отдельном сервере.
* DB_USER — имя пользователя базы данных.
* DB_PASSWORD — пароль пользователя базы данных.
* PG_USER — имя пользователя в PGAdmin.
* PG_PASSWORD — пароль пользователя в PGAdmin.
* UI_USER — имя пользователя платформы.
* UI_PASSWORD — пароль пользователя платформы.
* AUTH_KEY — секретный ключ для авторизации с использованием JWT-токена.
* COMPOSE_FILE — исходный docker-compose файл для развертывания системы.

Также убедитесь, что у порты, указанные в docker-compose файле, указанном в COMPOSE_FILE, не заняты в вашей системе. Вы можете изменить все порты, кроме сервиса `api`.

3) Соберите образы Docker:

Для этого выполните следующую команду:
```
$ docker-compose build --no-cache
```

4) Запустите контейнеры в фоновом режиме:
 
Для этого выполните команду:
```
$ docker-compose up --build -d
```

После успешного запуска система будет доступна по адресу: http://localhost:5173/kitoboy. Логин и пароль будет совпадать с теми, что были указаны в UI_USER и UI_PASSWORD

Взаимодействие с системой детально описано в [pdf-руководстве пользователя](./docs/user_guide.pdf).

### Данные для обработки: 
Наполнение системы данными происходит на основе загрузки файлов следующего формата:

- Формат: CSV
- Заголовки колонок отсутствуют - данные парсятся, начиная с первой строки
- Первая колонка - дата и время с тайм-зоной в формате UTC (напр. `2025-04-10T12:38:22.922Z`)
- Вторая колонка - текст

Пример файла можно найти в [репозитории](./docs/input_file_example.csv).
Остальные данные заполняются вручную через форму.

# Разработка

Для удобной разработки ниже описан способ запуска системы в режиме, когда активен Hot Module Reload (HMR) в сервисах Frontend и API.

1) Подготовить окружение

Подготовка идентична той, что указана в разделе "Запуск системы", за исключением того, что значение переменной `NODE_ENV` должно быть установлено в `development`.

2) Установить зависимости для Frontend:

Для этого выполните следующую команду:
```
$ cd frontend
$ npm i
```
3) Установить зависимости для API:

Для этого выполните следующие команды:
```
$ cd ../api
$ npm i
$ cd ..
```

4) Собрать образы Docker:

Для этого выполните следующую команду:
```
$ docker-compose build --no-cache
```
5) Запустить контейнеры:

Для этого выполните следующую команду:
```
$ docker-compose up --build
```

6) Запустить Frontend в контейнере:
```
$ docker-compose exec frontend sh
$ npm run dev 
```
Выход
```
$ cmd+c
$ exit  
```
Описание API библиотеки доступно в [pdf-руководстве разработчика](./docs/developer_guide.pdf).

# Перечень направлений использования библиотеки

1.  Анализ пользователей социальных сетей на предмет суицидального поведения на основе их текстовых публикаций с возможностью вынесения объяснимого решения о суицидальном статусе пользователя.
2.  Отслеживание динамики постов пресуицидального и антисуицидального характера у пользователей социальных сетей.
3.  Сбор и анализ персональной информации о пользователе на основе его текстов в социальных сетях.
4.  В общем случае, анализ серии текстовых публикаций человека при наличии соответствующей модели (эмоции, патологических психических состояний, степени удовлетворенности товаром и т. д.)

# Как еще можно использовать библиотеку

## Использование модуля "Зоопарк" в качестве бекэнда  для чатботов

Модуль "Зоопарк" (zoo) предоставляет единый интерфейс для инференса многих бертоподобных моделей классификации. Именно он ответственен за наполнение «Китобоя» предсказаниями моделей. Его можно использовать как самостоятельный компонент в других приложениях.

Здесь мы покажем, как мы используем Зоопарк вместе с ботом мессенджера Телеграм, который использовался для демонстрационных целей.

Далее предполагается, что вы будете использовать модели пресуицидальных и антисуицидальных сигналов. Также предполагается, что развертывание будет происходит на локальной машине и все необходимые зависимости установлены. Кроме того, предполагается, что у вас есть токен бота Telegram. Его получение описано в [официальной инструкции](https://core.telegram.org/bots/tutorial?ysclid=mi4r7efi1r993726290#obtain-your-bot-token).

Прежде, чем приступать к выполнению инструкции, убедитесь, что у вас свободны порты 8000, 8001, 8888, 8080. Проверить, что порт не занят, можно с помощью одной из команд (в зависимости от того, какая присутствует в системе):
```
$ sudo ss -tulnp | grep –w "8000"
$ sudo netstat -tulnp | grep –w "8000"
```
Если порт не занят, то вывод команд будет пустой. Если порт освободить нельзя, можно выбрать другой порт и использовать его во всех местах, где указан исходный. Также для простоты следования рекомендуется выключить систему «Китобой». Для этого в корне проекта следует выполнить команду:

```
docker-compose down
```

1. Запустить контейнеры с моделями
 
```
$ docker run -p 8000:8000 astromis/tritoned_presui_model-15:v1
$ docker run -p 8001:8000 astromis/tritoned_antisui_model-10:v1
```

2. В конфигурационном файле `./zoo/config/triton_services.yml` удалить все имеющиеся записи и прописать местонахождение моделей

```yaml
- ["http://localhost", "8000", "presui_model-15"]
- ["http://localhost", "8001", "antisui_model-10"]
```

3. В конфигурационном файле `./zoo/config/config.yml` установить значение `endpoint_to_send_preds` в `null`.

4. Создать окружение в корне проекта
```
$ python3 -m venv venv
$ source venv/bin/activate
$ pip install -r zoo/requirements.txt
```

5. Запустить Зоопарк командой (если необходимо смотреть за логами, а также иметь возможность автоперезагрузки сервера, то заменить `run` на `dev`)
```
$ cd zoo && fastapi run app/main.py --port=8888
```
6. Запустить контейнер с базой данных
```
$ docker run --name kitoboy_db -e POSTGRES_USER=kitoboy_user -e POSTGRES_PASSWORD=mysecretpassword -e POSTGRES_DB=kitoboy_db -p8080:5432 -d postgres:15-alpine
```
7. Вернуться в корень репозитория.
8. Установить в окружении зависимости бота 
```
$ pip install -r telegram_bot/requirements.txt
```
9. Если параметры запуска контейнера БД на шаге 7 отличаются от указанных, необходимо также заменить в файле `./telegram_bot/create_table.py` параметры базы данных в словаре на строчке 3.
10. Создать (проверить наличие) таблицу командой
```
$ python telegram_bot/create_table.py
```
11.  Указать в файле `./telegram_bot/bot_aiogram.py` токен бота (см. [официальную инструкцию](https://core.telegram.org/bots/tutorial?ysclid=mi4r7efi1r993726290#obtain-your-bot-token)) в строчке 155, а также параметры базы данных (если отличаются от п. 7) в словаре на строчке 157.
12. Запустить бота командой
```
$ python telegram_bot/bot_aiogram.py
```

После запуска в бот можно отсылать тексты, а бот будет присылать предсказанные сигналы с предложением оценить верность предсказания.

## Использование открытой библиотеки для анализа эмоционального состояния и динамики пользователей 

Систему можно использовать для анализа любых феноменов, поддающихся классификации. В это подразделе показано, как превратить систему в анализатор эмоций. За основу возьмем открытую [модель эмоций](cointegrated/rubert-tiny2-cedr-emotion-detection), обученную на датасете CEDR.


1. Клонируйте репозиторий `Tritoned Bert` в отдельную директорию, вне репозитория `Kitoboy`, и перейдите в сам репозиторий:
```
$ git clone https://github.com/psytechlab/tritoned_bert.git
$ cd tritoned_bert
```

2. Создайте и активируйте виртуальное окружение, затем установите необходимые зависимости:

```
# Создание виртуального окружения
python -m venv .venv
source .venv/bin/activate

# Установка Python-зависимостей
pip install -r requirements.txt

# Установка системных зависимостей
sudo apt-get update
sudo apt-get install -y gettext-base
```

3. В корневой директории репозитория создаем файл `id2label.json` следующего содержания
```json
{
    "0": "no_emotion", 
    "1": "joy", 
    "2": "sadness", 
    "3": "surprise", 
    "4": "fear",
    "5": "anger"
}
```
4. Выполняем команду для конвертации модели и создания Docker-образа:
```
$ ./make_triton_image.sh cointegrated/rubert-tiny2-cedr-emotion-detection cointegrated/rubert-tiny2-cedr-emotion-detection ./id2label.json cedr_emotion_model v1
```
5. Убедитесь, что у вас появился Docker-образ `tritoned_cedr_emotion_model:v1`. При выполнении команды `docker images | grep tritoned_cedr_emotion_model` должен появиться вывод, похожий на следующий:
```
tritoned_cedr_emotion_model          v1               bc012b0241ad   About a minute ago   1.34GB
```
6. Для запуска системы далее будет использоваться файл `docker-compose.cedr.production.yml`, который находится в корне репозитория Kitoboy. Он отличается тем, что в уровене `services` для простоты были удалены докеры моделей presui, antisui, pie, но был добавлен ранее созданный докер модели эмоций: 
```yml
# Контейнер с классификатором эмоций
cedr_emotion:
    image: tritoned_cedr_emotion_model:v1
    ports:
        - '5903:8000'
    healthcheck:
        test: ["CMD-SHELL", "curl -f http://localhost:8000/v2/health/ready | exit 1"]
        interval: 10s
        timeout: 5s
        retries: 20
    networks:
        - postgres
```
Кроме того на уровне `services.zoo.depends_on` были удалены все докеры, кроме `api`, и также добавлен докер `cedr_emotion`.
7. Если у вас еще нет файла `.env`, то создайте его так, как описано в разделе `Быстрый старт/Запуск системы/Подготовка окружения`.
8. В файле `.env` в последней строке задайте переменной `COMPOSE_FLE` значение  `docker-compose.cedr.production.yml`.
9. Убедитесь, что вы находитесь в корне репозитория `Kitoboy`.
10. Очистите файл `./zoo/config/triton_services.yml` и вставьте туда следующую строку
```
- ["http://cedr_emotion", "8000", "cedr_emotion_model"]
```
11. Очистите файл `./zoo/config/mapping.yml` и вставьте туда следующие строки
```
no_emotion: [нерелевантный, "#ffffff"]
joy: [радость, "#ffffff"]
sadness: [печаль, "#ffffff"]
surprise: [удивление, "#ffffff"]
fear: [страх, "#ffffff"]
anger: [злость, "#ffffff"]
```
12. В файле `./zoo/config/config.yml` замените значение `irrelevant_class_name` на `no_emotion`.
13. Находясь в корне репозитория kitoboy, запустите команды сборки докера и запуска контейнеры (пункты 3 и 4 раздела "Быстрый старт/Запуск системы").

Таким образом, система позволит определять эмоции пользовательских текстов и анализировать динамику эмоционального состояния.

## Адаптация и расширение функционала модуля поиска идентификационной информации

Модуль поиска идентификационной информации является составной частью библиотеки и может быть легко расширен за счет предоставляемого класса `AbstractIE`. В качестве примера разберем, как можно интегрировать большие языковые модели (БЯМ) в модуль.

Чтобы создать поисковик, необходимо отнаследоваться от класса `AbstractIE` и реализовать метод `make_prediction`. Допустим, имеется сервис `http://llm.ru`, который предоставляет доступ к БЯМ `llama-4-maverick` по OpenAI API. Было решено с помощью БЯМ искать любые упоминания данных российского паспорта. Тогда реализация класса БЯМ могла бы выглядеть следующим образом

```python
import requests
import json

class LlmIE(AbstractIE):

    def make_prediction(self, text: str) -> list[str]:
        json_data = {
            'model': "llama-4-maverick",
            'messages': [
                {
                    'role': 'system',
                    'content': "Определи, есть ли в тексте данные российского паспорта. В случае, если такие данные есть, напиши 'PASPORT'",
                },
                {
                    'role': 'user',
                    'content': text,
                },
            ],
        }
        response = requests.post("http://llm.ru//v1/chat/completions", 
                                headers= {'Content-Type': 'application/json','Authorization': f"Bearer TOKEN",},
                                json=json_data)
        return [json.loads(response_raw.text)["choices"][0]["message"]["content"]]
```

Для простоты можно сохранить этот класс в `./app/information_extraction.py` в конце.

После сохранения в файле `./app/main.py` необходимо импортировать новый класс и инициализировать его объект
```diff
+ from app.information_extraction import NavecIE, RegexIE, LlmIE

app = FastAPI()
app.state.ie_list = [
    NavecIE("data/navec_news_v1_1B_250K_300d_100q.tar", "data/slovnet_ner_news_v1.tar"),
    RegexIE("configs/regex_ie.yml"),
+   LlmIE()
]

```
Таким образом, после запуска сервиса для каждого текста будет использоваться БЯМ для поиска паспортных данных в текстах.
 
